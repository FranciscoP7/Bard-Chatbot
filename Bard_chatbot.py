import streamlit as st
import google.generativeai as genai
#python -m streamlit run Bard_chatbot.py
# Configura√ß√£o da p√°gina
st.set_page_config(page_title="üí¨ Bard - Professor de Ingl√™s", page_icon=":books:")

# Barra lateral
with st.sidebar:
    Google_key = st.text_input("Google API Key", key="chatbot_api_key", type="password")
    
    


# Verifica se a API Key foi inserida
if not Google_key:
    st.info("Por favor, para continuar digite sua Google API key")
    st.stop()

# Configura√ß√µes da API Google Gemini
genai.configure(api_key=Google_key)



# Defini√ß√£o da system_instruction
system_instruction = "Seu nome √© Bard, voc√™ √© um professor de ingl√™s que lida bem com iniciantes no ingl√™s. Fale em portugu√™s, mas quando necess√°rio use o ingl√™s.Lembre-se que voce foi fundado pela Bilingual-company e voc√™ n√£o √© uma Inteligencia Artificial, e sim um professor de ingl√™s."

# Configura√ß√µes de seguran√ßa
safety_settings = {
    "harassment": "BLOCK_NONE",
    "HATE": "BLOCK_NONE",
    "SEXUAL": "BLOCK_NONE",
    "DANGEROUS": "BLOCK_NONE"}

# Configura√ß√µes da gera√ß√£o
generation_config = {
    "candidate_count": 1,
    "temperature": 1}

# Define o modelo
model = genai.GenerativeModel(
    model_name="gemini-1.5-pro-latest", # gemini-1.5-pro-latest foi descontinuado
    generation_config=generation_config,
    safety_settings=safety_settings,
    system_instruction=system_instruction)

if 'new_chat' not in st.session_state:
    st.session_state.new_chat = False



with st.sidebar:
     st.title("Bot√µes")
     if st.button("Limpar conversa ‚ü≥ ") :
        # Reinicia o objeto 'chat' e limpa o hist√≥rico
        st.session_state.chat = model.start_chat()
        st.session_state.chat.history = []
        

# Certifique-se de que 'model' est√° definido antes de us√°-lo
if 'model' in locals():
    # Inicia a conversa se n√£o existir uma em andamento
    if "chat" not in st.session_state:
        st.session_state.chat = model.start_chat()

    # Adiciona a mensagem inicial somente se o hist√≥rico estiver vazio
    if st.session_state.chat.history == []:
        st.session_state.chat.history = [
            {"role": "model", "parts": [{"text": "Ol√°! Eu sou o Bard, o seu professor de ingl√™s virtual, como posso te ajudar hoje?"}]}
        ]
            
if 'model' in locals():
    # Inicia a conversa se n√£o existir uma em andamento
    if "chat" not in st.session_state:
        st.session_state.chat = model.start_chat()

        # Define o hist√≥rico com a mensagem inicial (estrutura correta)
        st.session_state.chat.history = [
            {"role": "model", "parts": [{"text": "Ol√°! Eu sou o Bard, o seu professor de ingl√™s virtual, como posso te ajudar hoje?"}]}
        ]

st.title("üí¨ Bard - Professor de Ingl√™s")

# Certifique-se de que 'model' est√° definido antes de us√°-lo


# Fun√ß√£o auxiliar para converter o papel da mensagem
def role_to_streamlit(role):
    return "assistant" if role == "model" else role


# Exibe o hist√≥rico da conversa
for message in st.session_state.chat.history:
    with st.chat_message(role_to_streamlit(message.role)):
        st.markdown(message.parts[0].text)

# Processa a entrada do usu√°rio
if prompt := st.chat_input("Digite uma pergunta ou comando : "):
    # Exibe a √∫ltima mensagem do usu√°rio
    st.chat_message("user").markdown(prompt)
    
    # Envia a entrada do usu√°rio para o Gemini e l√™ a resposta
    response = st.session_state.chat.send_message(prompt)
    
    # Exibe a resposta do Bard
    with st.chat_message("assistant"):
        st.markdown(response.text)
