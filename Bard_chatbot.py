import streamlit as st
import google.generativeai as genai
#python -m streamlit run Bard_chatbot.py
# ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(page_title="ğŸ’¬ Bard - Professor de InglÃªs", page_icon=":books:")

# Barra lateral
with st.sidebar:
    Google_key = st.text_input("API Key", key="chatbot_api_key", type="password")
    
    


# Verifica se a API Key foi inserida
if not Google_key:
    st.info("Por favor, para continuar digite sua Google API key")
    st.stop()

# ConfiguraÃ§Ãµes da API Google Gemini
genai.configure(api_key=Google_key)



# DefiniÃ§Ã£o da system_instruction
system_instruction = "Seu nome Ã© Bard, vocÃª Ã© um professor de inglÃªs que lida bem com iniciantes no inglÃªs. Fale em portuguÃªs, mas quando necessÃ¡rio use o inglÃªs.Lembre-se que voce foi fundado pela Bilingual-company e vocÃª nÃ£o Ã© uma Inteligencia Artificial, e sim um professor de inglÃªs."

# ConfiguraÃ§Ãµes de seguranÃ§a
safety_settings = {
    "harassment": "BLOCK_NONE",
    "HATE": "BLOCK_NONE",
    "SEXUAL": "BLOCK_NONE",
    "DANGEROUS": "BLOCK_NONE"}

# ConfiguraÃ§Ãµes da geraÃ§Ã£o
generation_config = {
    "candidate_count": 1,
    "temperature": 1}

# Define o modelo
model = genai.GenerativeModel(
    model_name="gemini-1.5-pro-latest", # gemini-1.5-pro-latest foi descontinuado
    generation_config=generation_config,
    safety_settings=safety_settings,
    system_instruction=system_instruction)

if 'new_chat' not in st.session_state:
    st.session_state.new_chat = False



with st.sidebar:
     st.title("BotÃµes")
     if st.button("Limpar conversa âŸ³ ") :
        # Reinicia o objeto 'chat' e limpa o histÃ³rico
        st.session_state.chat = model.start_chat()
        st.session_state.chat.history = []
        

# Certifique-se de que 'model' estÃ¡ definido antes de usÃ¡-lo
if 'model' in locals():
    # Inicia a conversa se nÃ£o existir uma em andamento
    if "chat" not in st.session_state:
        st.session_state.chat = model.start_chat()

    # Adiciona a mensagem inicial somente se o histÃ³rico estiver vazio
    if st.session_state.chat.history == []:
        st.session_state.chat.history = [
            {"role": "model", "parts": [{"text": "OlÃ¡! Eu sou o Bard, o seu professor de inglÃªs virtual, como posso te ajudar hoje?"}]}
        ]
            
if 'model' in locals():
    # Inicia a conversa se nÃ£o existir uma em andamento
    if "chat" not in st.session_state:
        st.session_state.chat = model.start_chat()

        # Define o histÃ³rico com a mensagem inicial (estrutura correta)
        st.session_state.chat.history = [
            {"role": "model", "parts": [{"text": "OlÃ¡! Eu sou o Bard, o seu professor de inglÃªs virtual, como posso te ajudar hoje?"}]}
        ]

st.title("ğŸ’¬ Bard - Professor de InglÃªs")

# Certifique-se de que 'model' estÃ¡ definido antes de usÃ¡-lo


# FunÃ§Ã£o auxiliar para converter o papel da mensagem
def role_to_streamlit(role):
    return "assistant" if role == "model" else role


# Exibe o histÃ³rico da conversa
for message in st.session_state.chat.history:
    with st.chat_message(role_to_streamlit(message.role)):
        st.markdown(message.parts[0].text)

# Processa a entrada do usuÃ¡rio
if prompt := st.chat_input("Digite uma pergunta ou comando : "):
    # Exibe a Ãºltima mensagem do usuÃ¡rio
    st.chat_message("user").markdown(prompt)
    
    # Envia a entrada do usuÃ¡rio para o Gemini e lÃª a resposta
    response = st.session_state.chat.send_message(prompt)
    
    # Exibe a resposta do Bard
    with st.chat_message("assistant"):
        st.markdown(response.text)
